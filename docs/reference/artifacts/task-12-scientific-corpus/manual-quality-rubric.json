{
  "auto_generated": true,
  "entries": [
    {
      "backend": "docling",
      "document_slug": "2025-emnlp-main-993-2ffebdb6",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "2025.emnlp-main.993.pdf"
    },
    {
      "backend": "docling",
      "document_slug": "are-large-language-models-reliable-argument-quality-annotato-fcbe2290",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Are Large Language Models Reliable Argument  Quality Annotators?.pdf"
    },
    {
      "backend": "docling",
      "document_slug": "best-practices-for-text-annotation-with-large-language-model-09c36567",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Best Practices for Text Annotation with Large Language Models.pdf"
    },
    {
      "backend": "docling",
      "document_slug": "can-large-language-models-capture-human-annotator-disagreeme-cf75b84f",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Can Large Language Models Capture Human Annotator Disagreements?.pdf"
    },
    {
      "backend": "docling",
      "document_slug": "dependence-aware-label-aggregation-for-llm-as-a-judge-via-is-bc244bc6",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Dependence-Aware Label Aggregation for LLM-as-a-Judge  via Ising Models.pdf"
    },
    {
      "backend": "docling",
      "document_slug": "judgebench-a-benchmark-for-evaluating-llm-based-judges-9f8194b8",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "JUDGEBENCH- A BENCHMARK FOR EVALUATING  LLM-BASED JUDGES.pdf"
    },
    {
      "backend": "docling",
      "document_slug": "language-models-in-the-loop-incorporating-prompting-into-wea-c3bb110a",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Language Models in the Loop - Incorporating Prompting into Weak Supervision.pdf"
    },
    {
      "backend": "docling",
      "document_slug": "meganno-a-human-llm-collaborative-annotation-system-530edb8d",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "MEGAnno+- A Human-LLM Collaborative Annotation System.pdf"
    },
    {
      "backend": "docling",
      "document_slug": "prompt-stability-scoring-for-text-annotation-with-large-lang-99b12312",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Prompt Stability Scoring for Text Annotation  with Large Language Models.pdf"
    },
    {
      "backend": "docling",
      "document_slug": "the-alternative-annotator-test-for-llm-as-a-judge-how-to-sta-d936662d",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "The Alternative Annotator Test for LLM-as-a-Judge-  How to Statistically Justify Replacing Human Annotators with LLMs .pdf"
    },
    {
      "backend": "pymupdf",
      "document_slug": "2025-emnlp-main-993-2ffebdb6",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "2025.emnlp-main.993.pdf"
    },
    {
      "backend": "pymupdf",
      "document_slug": "are-large-language-models-reliable-argument-quality-annotato-fcbe2290",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Are Large Language Models Reliable Argument  Quality Annotators?.pdf"
    },
    {
      "backend": "pymupdf",
      "document_slug": "best-practices-for-text-annotation-with-large-language-model-09c36567",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Best Practices for Text Annotation with Large Language Models.pdf"
    },
    {
      "backend": "pymupdf",
      "document_slug": "can-large-language-models-capture-human-annotator-disagreeme-cf75b84f",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Can Large Language Models Capture Human Annotator Disagreements?.pdf"
    },
    {
      "backend": "pymupdf",
      "document_slug": "dependence-aware-label-aggregation-for-llm-as-a-judge-via-is-bc244bc6",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Dependence-Aware Label Aggregation for LLM-as-a-Judge  via Ising Models.pdf"
    },
    {
      "backend": "pymupdf",
      "document_slug": "judgebench-a-benchmark-for-evaluating-llm-based-judges-9f8194b8",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "JUDGEBENCH- A BENCHMARK FOR EVALUATING  LLM-BASED JUDGES.pdf"
    },
    {
      "backend": "pymupdf",
      "document_slug": "language-models-in-the-loop-incorporating-prompting-into-wea-c3bb110a",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Language Models in the Loop - Incorporating Prompting into Weak Supervision.pdf"
    },
    {
      "backend": "pymupdf",
      "document_slug": "meganno-a-human-llm-collaborative-annotation-system-530edb8d",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "MEGAnno+- A Human-LLM Collaborative Annotation System.pdf"
    },
    {
      "backend": "pymupdf",
      "document_slug": "prompt-stability-scoring-for-text-annotation-with-large-lang-99b12312",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "Prompt Stability Scoring for Text Annotation  with Large Language Models.pdf"
    },
    {
      "backend": "pymupdf",
      "document_slug": "the-alternative-annotator-test-for-llm-as-a-judge-how-to-sta-d936662d",
      "information_retention": 3,
      "layout_fidelity": 3,
      "legibility": 3,
      "notes": "autogenerated placeholder rubric; replace with manual review notes.",
      "source_file": "The Alternative Annotator Test for LLM-as-a-Judge-  How to Statistically Justify Replacing Human Annotators with LLMs .pdf"
    }
  ],
  "generated_at": "2026-02-15T01:28:14Z",
  "weights": {
    "information_retention": 0.35,
    "layout_fidelity": 0.45,
    "legibility": 0.2
  }
}
